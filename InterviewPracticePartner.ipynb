{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MayankPandey2004/InterviewPracticePartner/blob/main/InterviewPracticePartner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ExrUf-SvvdLL"
      },
      "outputs": [],
      "source": [
        "!pip install --q pinecone openai autogen\n",
        "!pip install --q autogen-agentchat autogen-ext[openai,azure]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone\n",
        "from openai import OpenAI\n",
        "from typing import List\n",
        "from google.colab import userdata\n",
        "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
        "from autogen_agentchat.teams import SelectorGroupChat\n",
        "from autogen_agentchat.agents import UserProxyAgent"
      ],
      "metadata": {
        "id": "mDOTaBky1NCK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PINECONE_API_KEY = userdata.get('pinecone_api')\n",
        "OPENAI_API_KEY = userdata.get('openai_api_key')\n",
        "OPENAI_MODEL = \"gpt-4o-mini\"\n",
        "EMBEDDING_MODEL_ID = \"text-embedding-3-small\"\n",
        "DIMENSION = 512\n",
        "INDEX_HOST = \"https://interview-questions-pfcnu58.svc.aped-4627-b74a.pinecone.io\"\n",
        "INDEX_NAME = \"interview-questions\"\n",
        "DEFAULT_NAMESPACE = \"Frontend\"\n",
        "\n",
        "model_client = OpenAIChatCompletionClient(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        api_key=OPENAI_API_KEY,\n",
        "        max_tokens=2000\n",
        "    )"
      ],
      "metadata": {
        "id": "0W_gipuW1PW5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from typing import List\n",
        "\n",
        "def embed_query(openai_client: OpenAI, query_text: str) -> List[float]:\n",
        "    try:\n",
        "        response = openai_client.embeddings.create(\n",
        "            model=\"text-embedding-3-small\",\n",
        "            input=[query_text],\n",
        "            dimensions=DIMENSION\n",
        "        )\n",
        "        query_vector = response.data[0].embedding\n",
        "        return query_vector\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during embedding: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "8KhhiD3xqxp1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "index = pc.Index(host=INDEX_HOST)"
      ],
      "metadata": {
        "id": "dwQ2oVNe1guN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_pinecone_rag(query_text: str):\n",
        "    \"\"\"\n",
        "    Searches the Pinecone index with a query, embeds the text using\n",
        "    'text-embedding-3-small' (512 dimensions), and returns the retrieved documents.\n",
        "\n",
        "    Args:\n",
        "        query_text (str): The search query provided by the assistant agent.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string of the relevant document questions and answers.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Generate the vector (using the globally available embed_query with dimension 512)\n",
        "    # Note: If embed_query isn't accessible globally, define it inside or pass clients.\n",
        "    # We rely on the notebook structure here.\n",
        "    query_vector = embed_query(openai_client, query_text)\n",
        "\n",
        "    if not query_vector:\n",
        "        return \"Error: Could not generate embedding for the query.\"\n",
        "\n",
        "    # 2. Perform the Pinecone search (using the globally available index)\n",
        "    try:\n",
        "        # Using index.query with 'vector' argument, as per your successful previous attempt\n",
        "        # and including metadata (question/answer) in the results\n",
        "        res = index.query(\n",
        "            namespace=DEFAULT_NAMESPACE,\n",
        "            vector=query_vector,\n",
        "            top_k=3,\n",
        "            include_metadata=True,\n",
        "            include_values=False\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return f\"Error occurred during Pinecone query: {e}\"\n",
        "\n",
        "    # 3. Format the results\n",
        "    if not res.matches:\n",
        "        return \"No relevant documents found in the vector store.\"\n",
        "\n",
        "    context = []\n",
        "    for match in res.matches:\n",
        "        # Check if the match has required metadata fields\n",
        "        if 'question' in match.metadata and 'answer' in match.metadata:\n",
        "             context.append(f\"Question: {match.metadata['question']}\\nAnswer: {match.metadata['answer']}\")\n",
        "\n",
        "    # Send the raw context back to the LLM for synthesis\n",
        "    return \"\\n---\\n\".join(context)"
      ],
      "metadata": {
        "id": "_UU2yOl7so-r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interviewer = AssistantAgent(\n",
        "    name=\"interviewer\",\n",
        "    model_client = model_client,\n",
        "    # TOOLS REMOVED HERE\n",
        "    system_message=\"\"\"You are a professional RAG Interviewer. Your mission is to conduct a Frontend development interview using RAG context received from the other agents.\n",
        "1.  **START**: Receive the first question from the qa_handler_agent and immediately ask it to the Candidate.\n",
        "2.  **RESPONSE**: When the Candidate answers, you **MUST** follow this structured, multi-part response template for your analysis and next question:\n",
        "    ### üéØ Analysis and Next Question\n",
        "\n",
        "    #### üìù Analysis of Candidate's Answer\n",
        "    **Score**: [Brief rating/assessment based on the hidden stored Answer.]\n",
        "    **Evaluation**: [Contrast the Candidate's answer with the stored RAG Answer from the conversation history. Be critical but fair.]\n",
        "\n",
        "    <hr>\n",
        "\n",
        "    #### ‚ùì Next Question\n",
        "    **Strategy**: [State your reasoning: e.g., 'Follow-up on X' or 'Move to next topic Y'.]\n",
        "    [Ask the next question text here, ensuring it is sourced from your history or a new RAG call if needed.]\n",
        "\n",
        "3.  **Constraints**: You MUST adhere to the analysis structure. Do NOT reveal the stored Answer to the Candidate. Use the RAG context for all questions. Reply with 'TERMINATE' only when the interview is over.\"\"\"\n",
        ")\n",
        "retriever_agent= AssistantAgent(\n",
        "    name=\"retriever_agent\",\n",
        "    model_client = model_client,\n",
        "    tools = [search_pinecone_rag],\n",
        "    system_message=\"\"\"You are a professional RAG system acting as a **Retriever**.\n",
        "    1.  **Initial Action**: Use the 'search_pinecone_rag' tool with the query: 'Frontend development interview questions'.\n",
        "    2. **Send Data**: Send the raw output from the tool *directly* to the **qa_handler_agent**. Your task is complete after this step.\"\"\"\n",
        ")\n",
        "\n",
        "qa_handler_agent = AssistantAgent(\n",
        "    name=\"qa_handler_agent\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"\"\"You are a QA Handler. Your task is to process the raw RAG output received from the retriever_agent.\n",
        "    1. **Context Storage**: Store the **entire** incoming raw text (all Q/A pairs) in your memory.\n",
        "    2. **Question Extraction**: Extract the **first, clean question text** from the raw output.\n",
        "    3. **Output**: Output ONLY that single, extracted question text and send it directly to the **interviewer** agent. Do not include any context, headers, or conversational fillers.\"\"\"\n",
        ")\n",
        "candidate_proxy = UserProxyAgent(\n",
        "    name=\"Candidate\"\n",
        ")"
      ],
      "metadata": {
        "id": "ZqsBc0dzsrWS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selector_func_rag_interview(messages) -> str | None:\n",
        "    last_speaker_name = messages[-1].source\n",
        "\n",
        "    ALL_AGENTS = [interviewer.name, retriever_agent.name, candidate_proxy.name, qa_handler_agent.name]\n",
        "\n",
        "    if last_speaker_name not in ALL_AGENTS:\n",
        "        return retriever_agent.name\n",
        "\n",
        "    if last_speaker_name == retriever_agent.name:\n",
        "        return qa_handler_agent.name\n",
        "\n",
        "    if last_speaker_name == qa_handler_agent.name:\n",
        "        return interviewer.name\n",
        "\n",
        "    if last_speaker_name == interviewer.name:\n",
        "        return candidate_proxy.name\n",
        "\n",
        "    if last_speaker_name == candidate_proxy.name:\n",
        "        return interviewer.name\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "lkno-HKk8Rfv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "termination = MaxMessageTermination(max_messages=30) | TextMentionTermination(\"TERMINATE\")\n",
        "team = SelectorGroupChat(\n",
        "    [interviewer, retriever_agent, candidate_proxy,qa_handler_agent],\n",
        "    model_client=model_client,\n",
        "    termination_condition=termination,\n",
        "    selector_func=selector_func_rag_interview,\n",
        "    allow_repeated_speaker=True,\n",
        ")"
      ],
      "metadata": {
        "id": "jSvWe3ip8KIJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Fixed Agentic AI Interview System\n",
        "- Proper async handling for Colab\n",
        "- Tracks asked questions to avoid repetition\n",
        "- Better follow-up logic\n",
        "- Processing delays for better UX\n",
        "\"\"\"\n",
        "\n",
        "from enum import Enum\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Dict, List, Any\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from autogen_agentchat.messages import TextMessage\n",
        "\n",
        "class DifficultyLevel(Enum):\n",
        "    EASY = 1\n",
        "    MEDIUM = 2\n",
        "    HARD = 3\n",
        "\n",
        "@dataclass\n",
        "class Question:\n",
        "    question: str\n",
        "    expected_answer: str\n",
        "    difficulty: str\n",
        "    topic: str\n",
        "\n",
        "@dataclass\n",
        "class InterviewState:\n",
        "    questions_asked: List[Question]\n",
        "    user_answers: List[str]\n",
        "    scores: List[float]\n",
        "    current_difficulty: DifficultyLevel\n",
        "    topics_covered: set\n",
        "    asked_question_texts: set  # Track to avoid duplicates\n",
        "    total_questions: int = 0\n",
        "    max_questions: int = 8\n",
        "\n",
        "class InterviewSystem:\n",
        "    \"\"\"Main interview orchestrator\"\"\"\n",
        "\n",
        "    def __init__(self, openai_client_obj, pinecone_index, openai_api_key, namespace=\"Frontend\"):\n",
        "        self.openai_client = openai_client_obj\n",
        "        self.index = pinecone_index\n",
        "        self.namespace = namespace\n",
        "        self.api_key = openai_api_key\n",
        "\n",
        "        # Create fresh model client\n",
        "        self.model_client = OpenAIChatCompletionClient(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            api_key=openai_api_key,\n",
        "            max_tokens=2000\n",
        "        )\n",
        "\n",
        "        self.state = InterviewState(\n",
        "            questions_asked=[],\n",
        "            user_answers=[],\n",
        "            scores=[],\n",
        "            current_difficulty=DifficultyLevel.EASY,\n",
        "            topics_covered=set(),\n",
        "            asked_question_texts=set()\n",
        "        )\n",
        "\n",
        "    def _search_rag(self, query: str, top_k: int = 5) -> List[Dict]:\n",
        "        \"\"\"Search Pinecone for questions, returning multiple to choose from\"\"\"\n",
        "        from openai import OpenAI\n",
        "\n",
        "        # Embed query\n",
        "        openai_temp = OpenAI(api_key=self.api_key)\n",
        "        response = openai_temp.embeddings.create(\n",
        "            model=\"text-embedding-3-small\",\n",
        "            input=[query],\n",
        "            dimensions=512\n",
        "        )\n",
        "        query_vector = response.data[0].embedding\n",
        "\n",
        "        if not query_vector:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            res = self.index.query(\n",
        "                namespace=self.namespace,\n",
        "                vector=query_vector,\n",
        "                top_k=top_k,\n",
        "                include_metadata=True,\n",
        "                include_values=False\n",
        "            )\n",
        "\n",
        "            results = []\n",
        "            if res.matches:\n",
        "                for match in res.matches:\n",
        "                    if 'question' in match.metadata and 'answer' in match.metadata:\n",
        "                        q_text = match.metadata['question']\n",
        "\n",
        "                        # Skip if already asked\n",
        "                        if q_text in self.state.asked_question_texts:\n",
        "                            continue\n",
        "\n",
        "                        results.append({\n",
        "                            'question': q_text,\n",
        "                            'expected_answer': match.metadata['answer'],\n",
        "                            'difficulty': match.metadata.get('difficulty', 'medium'),\n",
        "                            'topic': match.metadata.get('topic', 'Frontend')\n",
        "                        })\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"RAG search error: {e}\")\n",
        "            return []\n",
        "\n",
        "    def run_interview(self):\n",
        "        \"\"\"Main interview loop\"\"\"\n",
        "\n",
        "        print(\"üéØ Starting Frontend Development Interview\")\n",
        "        print(\"=\" * 50)\n",
        "        print(\"\\nI'll ask you a series of questions. Answer to the best of your ability.\")\n",
        "        print(\"Type 'quit' to exit early.\\n\")\n",
        "\n",
        "        while self.state.total_questions < self.state.max_questions:\n",
        "            # Step 1: Get question from RAG\n",
        "            question_data = self._get_next_question()\n",
        "            if not question_data:\n",
        "                print(\"‚ùå Could not retrieve new question. Ending interview.\")\n",
        "                break\n",
        "\n",
        "            # Step 2: Ask the question\n",
        "            user_answer = self._ask_question(question_data['question'])\n",
        "            if user_answer.lower() in ['quit', 'exit', 'terminate']:\n",
        "                print(\"\\nüëã Interview ended early.\")\n",
        "                break\n",
        "\n",
        "            # Step 3: Evaluate the answer\n",
        "            evaluation = self._evaluate_answer_sync(\n",
        "                question_data['expected_answer'],\n",
        "                user_answer\n",
        "            )\n",
        "\n",
        "            # Step 4: Store results\n",
        "            self._update_state(question_data, user_answer, evaluation)\n",
        "\n",
        "            # Step 5: OPTIONAL follow-up (max 1 per question)\n",
        "            if evaluation.get('needs_followup', False) and evaluation.get('followup_question'):\n",
        "                followup_q = evaluation['followup_question']\n",
        "                print(f\"\\nüîç Follow-up: {followup_q}\")\n",
        "                followup_answer = input(\"Your answer: \")\n",
        "\n",
        "                # Processing delay for follow-up\n",
        "                if followup_answer.lower() not in ['quit', 'exit', 'skip']:\n",
        "                    print(\"\\n‚è≥ Processing\", end=\"\", flush=True)\n",
        "                    for _ in range(2):\n",
        "                        time.sleep(0.4)\n",
        "                        print(\".\", end=\"\", flush=True)\n",
        "                    print(\" ‚úì Follow-up noted.\\n\")\n",
        "                    time.sleep(0.5)\n",
        "\n",
        "            # Step 6: Decide next action\n",
        "            next_action = self._decide_next_step(evaluation)\n",
        "\n",
        "            if next_action['action'] == 'conclude':\n",
        "                break\n",
        "\n",
        "            # Update difficulty for next question\n",
        "            try:\n",
        "                self.state.current_difficulty = DifficultyLevel[next_action['next_difficulty'].upper()]\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Generate final report\n",
        "        self._generate_final_report()\n",
        "\n",
        "    def _get_next_question(self) -> Optional[Dict]:\n",
        "        \"\"\"Retrieve next question from RAG, avoiding repeats\"\"\"\n",
        "\n",
        "        # Build query with variety\n",
        "        difficulty_str = self.state.current_difficulty.name.lower()\n",
        "\n",
        "        # Try to get questions on new topics\n",
        "        covered_str = ', '.join(self.state.topics_covered) if self.state.topics_covered else ''\n",
        "\n",
        "        if covered_str:\n",
        "            query = f\"Frontend development {difficulty_str} interview question not about {covered_str}\"\n",
        "        else:\n",
        "            query = f\"Frontend development {difficulty_str} interview question\"\n",
        "\n",
        "        # Search RAG for multiple options\n",
        "        candidates = self._search_rag(query, top_k=10)\n",
        "\n",
        "        if not candidates:\n",
        "            # Fallback: try broader search\n",
        "            candidates = self._search_rag(\"Frontend interview question\", top_k=10)\n",
        "\n",
        "        # Return first unasked question\n",
        "        return candidates[0] if candidates else None\n",
        "\n",
        "    def _ask_question(self, question: str) -> str:\n",
        "        \"\"\"Ask question to user\"\"\"\n",
        "        print(f\"\\nüìù Question {self.state.total_questions + 1}:\")\n",
        "        print(f\"{question}\\n\")\n",
        "\n",
        "        answer = input(\"Your answer: \")\n",
        "\n",
        "        # Add processing delay with visual feedback\n",
        "        print(\"\\n‚è≥ Processing your answer\", end=\"\", flush=True)\n",
        "        for _ in range(3):\n",
        "            time.sleep(0.5)\n",
        "            print(\".\", end=\"\", flush=True)\n",
        "        print(\" Done!\\n\")\n",
        "\n",
        "        return answer\n",
        "\n",
        "    def _evaluate_answer_sync(self, expected: str, actual: str) -> Dict:\n",
        "        \"\"\"Evaluate answer using direct OpenAI API call\"\"\"\n",
        "        from openai import OpenAI\n",
        "\n",
        "        try:\n",
        "            client = OpenAI(api_key=self.api_key)\n",
        "\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"\"\"You are an expert technical interviewer evaluator.\n",
        "\n",
        "Evaluate the candidate's answer and provide ONLY a JSON response:\n",
        "{\n",
        "    \"score\": 0.0 to 1.0,\n",
        "    \"feedback\": \"brief 1-2 sentence evaluation\",\n",
        "    \"understanding_level\": \"excellent/good/partial/poor\",\n",
        "    \"needs_followup\": true/false,\n",
        "    \"followup_question\": \"one specific follow-up question if needed, otherwise null\"\n",
        "}\n",
        "\n",
        "Scoring rubric:\n",
        "- 0.9-1.0: Excellent, comprehensive answer covering all key points\n",
        "- 0.7-0.89: Good answer, minor gaps\n",
        "- 0.5-0.69: Partial understanding, missing key details\n",
        "- 0.3-0.49: Significant gaps\n",
        "- 0.0-0.29: Incorrect or minimal understanding\n",
        "\n",
        "Follow-ups should probe depth or clarify gaps, not repeat the question. Set needs_followup to true if answer was partial (0.4-0.7 range) and there's something specific to probe.\n",
        "\n",
        "Return ONLY valid JSON, no markdown, no other text.\"\"\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"\"\"Expected Answer: {expected}\n",
        "\n",
        "Candidate Answer: {actual}\n",
        "\n",
        "Evaluate and respond with JSON only.\"\"\"\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.3,\n",
        "                max_tokens=500\n",
        "            )\n",
        "\n",
        "            response_text = response.choices[0].message.content\n",
        "\n",
        "            # Parse JSON from response\n",
        "            # Remove markdown code blocks if present\n",
        "            response_text = re.sub(r'```json\\s*|\\s*```', '', response_text)\n",
        "            response_text = response_text.strip()\n",
        "\n",
        "            # Find JSON object\n",
        "            json_match = re.search(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', response_text, re.DOTALL)\n",
        "            if json_match:\n",
        "                eval_data = json.loads(json_match.group())\n",
        "                # Ensure score is float\n",
        "                eval_data['score'] = float(eval_data.get('score', 0.5))\n",
        "\n",
        "                # Ensure followup_question is None if not needed\n",
        "                if not eval_data.get('needs_followup', False):\n",
        "                    eval_data['followup_question'] = None\n",
        "\n",
        "                return eval_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Evaluation error: {e}\")\n",
        "\n",
        "        # Fallback: simple scoring\n",
        "        score = 0.6 if len(actual) > 50 else 0.4\n",
        "        return {\n",
        "            \"score\": score,\n",
        "            \"feedback\": \"Answer recorded and reviewed.\",\n",
        "            \"understanding_level\": \"partial\",\n",
        "            \"needs_followup\": False,\n",
        "            \"followup_question\": None\n",
        "        }\n",
        "\n",
        "    def _update_state(self, question_data: Dict, answer: str, evaluation: Dict):\n",
        "        \"\"\"Update interview state\"\"\"\n",
        "        q_obj = Question(\n",
        "            question=question_data['question'],\n",
        "            expected_answer=question_data['expected_answer'],\n",
        "            difficulty=question_data['difficulty'],\n",
        "            topic=question_data['topic']\n",
        "        )\n",
        "\n",
        "        self.state.questions_asked.append(q_obj)\n",
        "        self.state.user_answers.append(answer)\n",
        "        self.state.scores.append(evaluation['score'])\n",
        "        self.state.topics_covered.add(question_data['topic'])\n",
        "        self.state.asked_question_texts.add(question_data['question'])  # Track asked questions\n",
        "        self.state.total_questions += 1\n",
        "\n",
        "        print(f\"\\n‚úì Score: {evaluation['score']:.2f}\")\n",
        "        print(f\"üí¨ Feedback: {evaluation['feedback']}\")\n",
        "\n",
        "    def _decide_next_step(self, evaluation: Dict) -> Dict:\n",
        "        \"\"\"Decide next action\"\"\"\n",
        "\n",
        "        avg_score = sum(self.state.scores) / len(self.state.scores) if self.state.scores else 0\n",
        "\n",
        "        if self.state.total_questions >= self.state.max_questions:\n",
        "            return {\"action\": \"conclude\", \"next_difficulty\": \"medium\", \"next_topic\": \"any\"}\n",
        "\n",
        "        # Adaptive difficulty\n",
        "        if avg_score >= 0.8:\n",
        "            next_diff = \"hard\"\n",
        "        elif avg_score >= 0.6:\n",
        "            next_diff = \"medium\"\n",
        "        else:\n",
        "            next_diff = \"easy\"\n",
        "\n",
        "        return {\n",
        "            \"action\": \"continue\",\n",
        "            \"next_difficulty\": next_diff,\n",
        "            \"next_topic\": \"any\",\n",
        "            \"reasoning\": f\"Performance is {avg_score:.2f}\"\n",
        "        }\n",
        "\n",
        "    def _generate_final_report(self):\n",
        "        \"\"\"Generate and display final interview report\"\"\"\n",
        "\n",
        "        if not self.state.scores:\n",
        "            print(\"\\n‚ùå No questions completed.\")\n",
        "            return\n",
        "\n",
        "        avg_score = sum(self.state.scores) / len(self.state.scores)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"üìä INTERVIEW COMPLETE - FINAL REPORT\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        print(f\"\\nüìà Overall Score: {avg_score:.2f}/1.00 ({avg_score*100:.1f}%)\")\n",
        "\n",
        "        if avg_score >= 0.8:\n",
        "            level = \"Excellent ‚≠ê\"\n",
        "        elif avg_score >= 0.6:\n",
        "            level = \"Good ‚úì\"\n",
        "        elif avg_score >= 0.4:\n",
        "            level = \"Fair ~\"\n",
        "        else:\n",
        "            level = \"Needs Improvement ‚ö†Ô∏è\"\n",
        "\n",
        "        print(f\"üéØ Performance Level: {level}\")\n",
        "        print(f\"‚ùì Questions Answered: {self.state.total_questions}\")\n",
        "        print(f\"üìö Topics Covered: {', '.join(self.state.topics_covered)}\")\n",
        "\n",
        "        print(\"\\nüìù Question Breakdown:\")\n",
        "        for i, (q, score) in enumerate(zip(self.state.questions_asked, self.state.scores), 1):\n",
        "            emoji = \"üü¢\" if score >= 0.7 else \"üü°\" if score >= 0.5 else \"üî¥\"\n",
        "            print(f\"  {emoji} Q{i}. [{q.topic}] {score:.2f}\")\n",
        "\n",
        "        print(\"\\nüí° Recommendations:\")\n",
        "        weak_topics = [q.topic for q, s in zip(self.state.questions_asked, self.state.scores) if s < 0.6]\n",
        "        if weak_topics:\n",
        "            print(f\"  üìö Focus on: {', '.join(set(weak_topics))}\")\n",
        "        else:\n",
        "            print(\"  üéâ Great job! Keep practicing to maintain proficiency.\")\n",
        "\n",
        "        strong_topics = [q.topic for q, s in zip(self.state.questions_asked, self.state.scores) if s >= 0.8]\n",
        "        if strong_topics:\n",
        "            print(f\"  üí™ Strong areas: {', '.join(set(strong_topics))}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "interview_system = InterviewSystem(openai_client, index, OPENAI_API_KEY, DEFAULT_NAMESPACE)\n",
        "interview_system.run_interview()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5OY_XRNJQOO",
        "outputId": "230b2e54-9ba6-4fe2-bd5e-76426570af73"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Starting Frontend Development Interview\n",
            "==================================================\n",
            "\n",
            "I'll ask you a series of questions. Answer to the best of your ability.\n",
            "Type 'quit' to exit early.\n",
            "\n",
            "\n",
            "üìù Question 1:\n",
            "How can Web Components be used in front-end development, and what are the key specifications involved in creating them?\n",
            "\n",
            "Your answer: Web Components allow developers to create reusable, encapsulated, and framework-independent UI elements. They are used to build custom UI widgets, design systems, micro-frontends, and components that work in any framework (React, Angular, Vue) or plain HTML.\n",
            "\n",
            "‚è≥ Processing your answer... Done!\n",
            "\n",
            "\n",
            "‚úì Score: 0.70\n",
            "üí¨ Feedback: The candidate provided a good overview of Web Components and their use cases but missed key technical details about the specifications and implementation.\n",
            "\n",
            "üîç Follow-up: Can you explain the role of Shadow DOM in Web Components and how it contributes to encapsulation?\n",
            "Your answer: quit\n",
            "\n",
            "üìù Question 2:\n",
            "What are web workers and how can they improve performance?\n",
            "\n",
            "Your answer: quit\n",
            "\n",
            "‚è≥ Processing your answer... Done!\n",
            "\n",
            "\n",
            "üëã Interview ended early.\n",
            "\n",
            "==================================================\n",
            "üìä INTERVIEW COMPLETE - FINAL REPORT\n",
            "==================================================\n",
            "\n",
            "üìà Overall Score: 0.70/1.00 (70.0%)\n",
            "üéØ Performance Level: Good ‚úì\n",
            "‚ùì Questions Answered: 1\n",
            "üìö Topics Covered: Frontend\n",
            "\n",
            "üìù Question Breakdown:\n",
            "  üü¢ Q1. [Frontend] 0.70\n",
            "\n",
            "üí° Recommendations:\n",
            "  üéâ Great job! Keep practicing to maintain proficiency.\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}